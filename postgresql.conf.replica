# ===================================================
# PostgreSQL 14 Replica Server Configuration
# WMS Analytics System - Logical Replication Target
# Сервер: 16 vCPU, 64 GB RAM, 2TB SSD
# 
# ВАЖНО: В системе отсутствует партиционирование таблиц
# Настройки enable_partitionwise_* отключены
# 
# КОНФИГУРАЦИЯ ДЛЯ РАБОТЫ НА VMWARE ESXI
# Primary и Replica работают на разных виртуальных машинах
# Оптимизировано для гипервизора VMware ESXi
# ===================================================

# ===================================================
# СЕТЕВЫЕ НАСТРОЙКИ И АУТЕНТИФИКАЦИЯ
# ===================================================

# Сетевые интерфейсы для подключения
# '*' означает, что PostgreSQL будет слушать на всех доступных сетевых интерфейсах
# Это необходимо для подключения BI-инструментов и аналитических приложений
# На отдельной VM это безопасно, так как доступ контролируется на уровне сети
listen_addresses = '*'

# Порт для подключения к базе данных
# 5432 - стандартный порт PostgreSQL
# На разных VM можно использовать одинаковые порты
port = 5432

# Максимальное количество одновременных подключений
# Для аналитического сервера требуется больше подключений, так как:
# - BI-инструменты создают множественные соединения
# - Параллельные запросы используют отдельные соединения
# - Аналитические отчеты могут выполняться одновременно
# Рекомендуется: (CPU cores * 4) + (RAM GB * 2) = (16 * 4) + (64 * 2) = 192
max_connections = 300

# ===================================================
# НАСТРОЙКИ ПАМЯТИ - ОПТИМИЗИРОВАНЫ ДЛЯ АНАЛИТИКИ
# ===================================================

# Размер разделяемой памяти (shared_buffers)
# Это основной буфер PostgreSQL, который хранит:
# - Часто используемые страницы данных
# - Индексы в памяти
# - Служебные структуры
# Рекомендуется: 25-40% от общего объема RAM
# Для 64GB: 64GB * 0.35 = 22.4GB, но ограничиваем 20GB для стабильности
shared_buffers = 20GB

# Память для операций сортировки и соединений (work_mem)
# Каждый параллельный процесс может использовать эту память для:
# - Сортировки больших наборов данных
# - Hash-соединений таблиц
# - Создания временных структур
# Рекомендуется: (RAM - shared_buffers) / (max_parallel_workers * 2)
# Для 64GB: (64GB - 20GB) / (16 * 2) = 44GB / 32 = 1.375GB
work_mem = 1GB

# Память для операций обслуживания (maintenance_work_mem)
# Используется для:
# - Создания индексов
# - Операций VACUUM
# - Анализа статистики
# - Обновления материализованных представлений
# Рекомендуется: 2-4GB для больших таблиц
maintenance_work_mem = 4GB

# Эффективный размер кэша операционной системы (effective_cache_size)
# Это не реальная память, а подсказка планировщику о том, сколько памяти
# доступно для кэширования данных на уровне ОС
# Рекомендуется: 75-80% от общего объема RAM
# Для 64GB: 64GB * 0.8 = 51.2GB
effective_cache_size = 50GB

# ===================================================
# НАСТРОЙКИ ЛОГИЧЕСКОЙ РЕПЛИКАЦИИ
# ===================================================

# Уровень WAL для логической репликации
# 'logical' необходим для:
# - Создания публикаций (publications)
# - Подписок (subscriptions)
# - Репликации изменений на уровне строк
# - Поддержки различных схем на primary и replica
wal_level = logical

# Максимальное количество работников логической репликации
# Каждый работник обрабатывает изменения из одной публикации
# Рекомендуется: количество публикаций + 2 (для резерва)
# Для WMS системы: 5 основных схем + 2 = 7
max_logical_replication_workers = 8

# Общее количество рабочих процессов
# Включает все типы работников: логические, параллельные, автовакуум
# Рекомендуется: (CPU cores * 2) + 10 = (16 * 2) + 10 = 42
max_worker_processes = 42

# Максимальное количество параллельных работников
# Параллельные работники выполняют:
# - Параллельные сканирования таблиц (без партиционирования)
# - Параллельные соединения (hash, nested loop, merge)
# - Параллельную агрегацию и сортировку
# - Параллельное выполнение UNION/UNION ALL
# Рекомендуется: количество CPU ядер = 16
max_parallel_workers = 16

# Максимальное количество работников на один параллельный запрос
# Ограничивает количество параллельных процессов для одного запроса
# Для таблиц без партиционирования каждый работник обрабатывает
# свою часть таблицы (по диапазону строк)
# Рекомендуется: количество CPU ядер = 16
max_parallel_workers_per_gather = 16

# ===================================================
# ОПТИМИЗАЦИЯ ДЛЯ АНАЛИТИЧЕСКИХ ЗАПРОСОВ
# ===================================================

# Стоимость случайного доступа к странице (random_page_cost)
# Для SSD дисков случайный доступ почти так же быстр, как последовательный
# Стандартное значение 4.0 слишком высоко для SSD
# Рекомендуется для SSD: 1.0-1.1
random_page_cost = 1.1

# Стоимость последовательного доступа к странице (seq_page_cost)
# Базовая стоимость для последовательного сканирования
# Обычно оставляют как есть для относительных сравнений
seq_page_cost = 1.0

# Стоимость обработки одного кортежа (cpu_tuple_cost)
# Влияет на выбор плана выполнения:
# - Низкие значения предпочитают операции с большим количеством кортежей
# - Высокие значения предпочитают операции с меньшим количеством кортежей
# Для аналитических запросов с большими таблицами снижаем
cpu_tuple_cost = 0.01

# Стоимость обработки индексированного кортежа (cpu_index_tuple_cost)
# Стоимость получения кортежа через индекс
# Обычно меньше cpu_tuple_cost, так как индекс уже прочитан
cpu_index_tuple_cost = 0.005

# Стоимость выполнения оператора (cpu_operator_cost)
# Стоимость вычислений (сравнения, арифметика, функции)
# Для аналитических запросов с множественными вычислениями снижаем
cpu_operator_cost = 0.0025

# Параллельность ввода-вывода (effective_io_concurrency)
# Количество одновременных операций ввода-вывода
# Для SSD дисков можно установить высокие значения
# Рекомендуется: количество CPU ядер * 20 = 16 * 20 = 320
effective_io_concurrency = 320

# Целевая статистика для планировщика (default_statistics_target)
# Влияет на точность планирования запросов:
# - Высокие значения = более точные планы, но медленнее ANALYZE
# - Низкие значения = быстрее ANALYZE, но менее точные планы
# Для аналитических запросов важна точность планирования
default_statistics_target = 500

# ===================================================
# НАСТРОЙКИ CHECKPOINT И WAL
# ===================================================

# Интервал между автоматическими checkpoint (checkpoint_timeout)
# Checkpoint - это процесс записи всех измененных страниц на диск
# Для аналитического сервера можно установить больший интервал:
# - Меньше нагрузки на диск
# - Больше времени для группировки изменений
# Рекомендуется: 15-30 минут
checkpoint_timeout = 30min

# Цель завершения checkpoint (checkpoint_completion_target)
# Распределяет I/O операции checkpoint во времени:
# - 0.9 означает, что 90% времени между checkpoint будет использовано для записи
# - Остальные 10% - для обычных операций
# Это снижает пиковую нагрузку на диск
checkpoint_completion_target = 0.9

# Предупреждение о медленном checkpoint (checkpoint_warning)
# Логирует предупреждение, если checkpoint занимает больше указанного времени
# Помогает выявить проблемы с производительностью диска
checkpoint_warning = 60s

# Размер буфера WAL (wal_buffers)
# Буфер для записи WAL записей перед сбросом на диск
# Рекомендуется: 16MB - 128MB
# Для аналитического сервера с большим количеством изменений: 128MB
wal_buffers = 128MB

# ===================================================
# ПАРАЛЛЕЛЬНОЕ ВЫПОЛНЕНИЕ ЗАПРОСОВ
# ===================================================

# Партиционированные соединения (enable_partitionwise_join)
# ОТКЛЮЧЕНО: В системе отсутствует партиционирование таблиц
# Если в будущем будет добавлено партиционирование, включить для:
# - Параллельной обработки партиций
# - Улучшения производительности больших таблиц
# - Оптимизации соединений по партициям
enable_partitionwise_join = off

# Партиционированная агрегация (enable_partitionwise_aggregate)
# ОТКЛЮЧЕНО: В системе отсутствует партиционирование таблиц
# Если в будущем будет добавлено партиционирование, включить для:
# - Параллельной агрегации по партициям
# - Ускорения GROUP BY операций
# - Оптимизации аналитических запросов
enable_partitionwise_aggregate = off

# Параллельные hash соединения (enable_parallel_hash)
# Hash соединения выполняются параллельно несколькими работниками
# Эффективно для соединения больших таблиц без партиционирования
# Включаем для улучшения производительности соединений
enable_parallel_hash = on

# Параллельное добавление (enable_parallel_append)
# Параллельное выполнение UNION ALL запросов
# Эффективно для объединения результатов нескольких подзапросов
# Не требует партиционирования таблиц
enable_parallel_append = on

# Параллельные объединения (enable_parallel_union)
# Параллельное выполнение операций UNION
# Ускоряет объединение результатов нескольких запросов
enable_parallel_union = on

# Параллельное сканирование (enable_parallel_scan)
# Параллельное сканирование больших таблиц
# Каждый работник сканирует свою часть таблицы
# Основной способ ускорения сканирования без партиционирования
enable_parallel_scan = on

# ===================================================
# ОПТИМИЗАЦИЯ ПЛАНИРОВЩИКА ЗАПРОСОВ
# ===================================================

# Материализация (enable_material)
# Позволяет планировщику создавать временные материализованные результаты
# Полезно для сложных запросов с множественными подзапросами
enable_material = on

# Hash агрегация (enable_hashagg)
# Использует hash-таблицы для группировки и агрегации
# Эффективно для больших таблиц с множественными группами
enable_hashagg = on

# Hash соединения (enable_hashjoin)
# Hash соединения эффективны для соединения больших таблиц
# Когда одна таблица помещается в память
enable_hashjoin = on

# Вложенные циклы (enable_nestloop)
# Классический алгоритм соединения для небольших таблиц
# Эффективен, когда одна таблица очень мала
enable_nestloop = on

# Слияние соединений (enable_mergejoin)
# Эффективно для соединения отсортированных таблиц
# Требует предварительной сортировки
enable_mergejoin = on

# Сканирование по индексу (enable_indexscan)
# Использование индексов для поиска данных
# Основной способ оптимизации запросов
enable_indexscan = on

# Только индексное сканирование (enable_indexonlyscan)
# Когда все необходимые данные содержатся в индексе
# Самый быстрый способ получения данных
enable_indexonlyscan = on

# Битмап сканирование (enable_bitmapscan)
# Комбинирует несколько индексов для сложных условий WHERE
# Эффективно для запросов с множественными условиями
enable_bitmapscan = on

# ===================================================
# НАСТРОЙКИ ЛОГИРОВАНИЯ И МОНИТОРИНГА
# ===================================================

# Направление вывода логов
# 'stderr' - логи выводятся в стандартный поток ошибок
# Это стандартный способ для systemd сервисов
log_destination = 'stderr'

# Включение сбора логов
# PostgreSQL будет создавать файлы логов в указанной директории
logging_collector = on

# Директория для хранения логов
# Относительно data_directory
log_directory = 'log'

# Шаблон имени файла лога
# %Y - год, %m - месяц, %d - день, %H - час, %M - минута, %S - секунда
log_filename = 'postgresql-replica-%Y-%m-%d_%H%M%S.log'

# Ротация логов по времени
# Создание нового файла лога каждый день
log_rotation_age = 1d

# Ротация логов по размеру
# Создание нового файла при достижении 100MB
log_rotation_size = 100MB

# Минимальная длительность запроса для логирования (в миллисекундах)
# Логируются только запросы, выполняющиеся дольше указанного времени
# Для аналитического сервера устанавливаем 5 секунд
log_min_duration_statement = 5000

# Логирование checkpoint операций
# Помогает мониторить производительность диска
log_checkpoints = on

# Логирование подключений
# Записывает информацию о каждом подключении/отключении
log_connections = on

# Логирование отключений
# Записывает причину отключения клиента
log_disconnections = on

# Логирование блокировок
# Записывает информацию о запросах, ожидающих освобождения блокировок
log_lock_waits = on

# Логирование временных файлов
# Записывает создание временных файлов (признак нехватки памяти)
log_temp_files = 0

# Логирование всех операций автовакуума
# Автовакуум - автоматическая очистка и анализ таблиц
log_autovacuum_min_duration = 0

# ===================================================
# НАСТРОЙКИ АВТОВАКУУМА ДЛЯ АНАЛИТИКИ
# ===================================================

# Включение автовакуума
# Автоматически очищает "мертвые" кортежи и обновляет статистику
autovacuum = on

# Максимальное количество процессов автовакуума
# Каждый процесс может обрабатывать одну таблицу
# Рекомендуется: количество CPU ядер / 2 = 16 / 2 = 8
autovacuum_max_workers = 8

# Интервал между запусками автовакуума
# Как часто проверять необходимость автовакуума
# Для аналитического сервера: 15 секунд
autovacuum_naptime = 15s

# Порог для запуска автовакуума (количество измененных кортежей)
# Автовакуум запускается, когда количество изменений превышает этот порог
# Для больших таблиц устанавливаем высокий порог
autovacuum_vacuum_threshold = 100

# Порог для запуска анализа (количество измененных кортежей)
# Анализ обновляет статистику для планировщика запросов
autovacuum_analyze_threshold = 100

# Масштабный коэффициент для вакуума
# Дополнительный порог: количество кортежей * коэффициент
# Для больших таблиц: 0.3 (30% от размера таблицы)
autovacuum_vacuum_scale_factor = 0.3

# Масштабный коэффициент для анализа
# Аналогично вакууму, но для анализа
autovacuum_analyze_scale_factor = 0.2

# ===================================================
# НАСТРОЙКИ ПРОИЗВОДИТЕЛЬНОСТИ ДЛЯ АНАЛИТИКИ
# ===================================================

# Синхронность коммитов (synchronous_commit)
# 'off' означает асинхронные коммиты:
# - Запрос завершается сразу после записи в WAL
# - Данные могут быть потеряны при сбое сервера
# - Значительно повышает производительность
# Для аналитического сервера приемлемо
synchronous_commit = off

# Задержка группового коммита (commit_delay)
# Задержка в микросекундах для группировки коммитов
# 0 означает отключение группировки
commit_delay = 0

# Минимальное количество транзакций для группового коммита
# При асинхронных коммитах не используется
commit_siblings = 1

# ===================================================
# НАСТРОЙКИ СЕТЕВЫХ СОЕДИНЕНИЙ
# ===================================================

# TCP keepalive - время до отправки первого keepalive пакета (в секундах)
# Помогает обнаружить "мертвые" соединения
tcp_keepalives_idle = 600

# Интервал между keepalive пакетами (в секундах)
tcp_keepalives_interval = 30

# Количество keepalive пакетов до разрыва соединения
tcp_keepalives_count = 3

# ===================================================
# НАСТРОЙКИ ВРЕМЕННЫХ ЗОН И ЛОКАЛИ
# ===================================================

# Временная зона сервера
# UTC рекомендуется для серверов баз данных
timezone = 'UTC'

# Локаль для сообщений
lc_messages = 'en_US.UTF-8'

# Локаль для денежных значений
lc_monetary = 'en_US.UTF-8'

# Локаль для числовых значений
lc_numeric = 'en_US.UTF-8'

# Локаль для временных значений
lc_time = 'en_US.UTF-8'

# Конфигурация текстового поиска по умолчанию
default_text_search_config = 'pg_catalog.english'

# ===================================================
# НАСТРОЙКИ WAL ДЛЯ REPLICA СЕРВЕРА
# ===================================================

# Уровень WAL для replica
# 'minimal' достаточно для replica, так как:
# - WAL не используется для восстановления
# - Логическая репликация работает через подписки
# - Экономится место на диске
wal_level = minimal

# Максимальное количество WAL отправителей
# На replica сервере не нужны, так как он не отправляет WAL
max_wal_senders = 0

# Максимальное количество слотов репликации
# На replica сервере не нужны
max_replication_slots = 0

# ===================================================
# НАСТРОЙКИ БЕЗОПАСНОСТИ ДЛЯ РАБОТЫ НА РАЗНЫХ VM
# ===================================================

# SSL соединения
# Рекомендуется включить для безопасного соединения между VM
# Требует настройки SSL сертификатов
ssl = on

# SSL сертификат сервера
# Путь к файлу сертификата (настроить в соответствии с вашей инфраструктурой)
ssl_cert_file = '/etc/ssl/certs/ssl-cert-snakeoil.pem'

# SSL приватный ключ
# Путь к приватному ключу (настроить в соответствии с вашей инфраструктурой)
ssl_key_file = '/etc/ssl/private/ssl-cert-snakeoil.key'

# Минимальная версия SSL/TLS
# Требует TLS 1.2 или выше для безопасности
ssl_min_protocol_version = 'TLSv1.2'

# Предпочитаемые шифры SSL
# Современные шифры для безопасности и производительности
ssl_ciphers = 'HIGH:MEDIUM:+3DES:!aNULL'

# ===================================================
# НАСТРОЙКИ СЕТЕВОЙ ПРОИЗВОДИТЕЛЬНОСТИ ДЛЯ VM
# ===================================================

# Размер TCP буфера для отправки
# Увеличиваем для лучшей производительности сетевого соединения
# Рекомендуется для VM с быстрым сетевым соединением
tcp_send_buffer_size = 16MB

# Размер TCP буфера для приема
# Увеличиваем для лучшей производительности сетевого соединения
# Рекомендуется для VM с быстрым сетевым соединением
tcp_recv_buffer_size = 16MB

# Таймаут для сетевых операций
# Увеличиваем для стабильности соединения между VM
# Особенно важно при медленном сетевом соединении
tcp_keepalives_idle = 600
tcp_keepalives_interval = 30
tcp_keepalives_count = 3

# ===================================================
# НАСТРОЙКИ ПРОИЗВОДИТЕЛЬНОСТИ ДЛЯ VMWARE ESXI
# ===================================================

# Размер страницы для shared_buffers
# Для VMware ESXi VM рекомендуется использовать стандартный размер страницы
# ESXi лучше работает со стандартными страницами памяти
huge_pages = off

# Настройки для работы с виртуализированным I/O в ESXi
# Увеличиваем таймауты для стабильности в VM среде
# ESXi может временно приостанавливать VM для миграции или обслуживания
deadlock_timeout = 1s

# Таймаут для блокировок
# Увеличиваем для стабильности в VM среде ESXi
# При миграции VM могут возникать временные задержки
lock_timeout = 0

# Таймаут для выполнения запросов
# Увеличиваем для сложных аналитических запросов
# ESXi может влиять на производительность CPU
statement_timeout = 0

# Настройки для оптимизации работы с ESXi
# Увеличиваем таймаут для операций ввода-вывода
# ESXi может кэшировать I/O операции
io_timeout = 30s

# Настройки для работы с виртуализированными дисками
# ESXi предоставляет виртуальные SCSI диски
# Оптимизируем настройки для виртуализированного I/O
effective_io_concurrency = 320

# Настройки checkpoint для ESXi
# ESXi может влиять на производительность диска
# Увеличиваем интервал для снижения нагрузки
checkpoint_timeout = 30min

# Настройки WAL для ESXi
# ESXi может кэшировать WAL операции
# Оптимизируем размер буфера
wal_buffers = 128MB

# ===================================================
# ДОПОЛНИТЕЛЬНЫЕ НАСТРОЙКИ ДЛЯ АНАЛИТИЧЕСКОГО СЕРВЕРА
# ===================================================

# Максимальный размер временных файлов
# Для аналитических запросов может потребоваться много временных файлов
# 0 означает неограниченный размер
temp_file_limit = 0

# Размер временных файлов для логирования
# Логируем все временные файлы для мониторинга производительности
log_temp_files = 0

# Статистика выполнения запросов
# Включаем для анализа производительности аналитических запросов
track_activities = on

# Статистика по функциям
# Включаем для анализа производительности пользовательских функций
track_functions = all

# Статистика по вводу-выводу
# Включаем для мониторинга дисковых операций
track_io_timing = on

# Статистика по запросам
# Включаем для анализа медленных запросов
pg_stat_statements.track = all

# ===================================================
# СПЕЦИФИЧНЫЕ НАСТРОЙКИ ДЛЯ VMWARE ESXI
# ===================================================

# Настройки для работы с виртуализированными дисками ESXi
# ESXi предоставляет виртуальные SCSI диски с различными типами
# Оптимизируем настройки для лучшей производительности

# Размер страницы для операций ввода-вывода
# Для ESXi VM рекомендуется использовать стандартный размер
# Это обеспечивает лучшую совместимость с виртуализацией
wal_block_size = 8192

# Настройки для работы с ESXi vMotion
# При миграции VM могут возникать временные задержки
# Увеличиваем таймауты для стабильности
idle_in_transaction_session_timeout = 0

# Настройки для работы с ESXi DRS (Distributed Resource Scheduler)
# ESXi может перемещать VM между хостами
# Оптимизируем настройки для стабильности
log_min_duration_statement = 5000

# Настройки для работы с ESXi HA (High Availability)
# При перезапуске VM на другом хосте
# Увеличиваем таймауты для восстановления
tcp_keepalives_idle = 600
tcp_keepalives_interval = 30
tcp_keepalives_count = 3

# Настройки для мониторинга производительности в ESXi
# Включаем детальное логирование для анализа
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
log_temp_files = 0

# Настройки для работы с ESXi Storage vMotion
# При миграции дисков могут возникать задержки
# Оптимизируем настройки I/O
effective_io_concurrency = 320
random_page_cost = 1.1
seq_page_cost = 1.0

# Настройки для работы с ESXi Snapshots
# При создании снапшотов могут возникать задержки
# Увеличиваем таймауты для стабильности
checkpoint_timeout = 30min
checkpoint_completion_target = 0.9

# ===================================================
# РЕКОМЕНДАЦИИ ПО НАСТРОЙКЕ VMWARE ESXI
# ===================================================

# ВАЖНО: Для оптимальной работы PostgreSQL на ESXi необходимо настроить:

# 1. Настройки VM:
#    - CPU: Reserve CPU resources для PostgreSQL VM
#    - Memory: Reserve memory для PostgreSQL VM
#    - Disk: Использовать Thick Provisioning для data дисков
#    - Network: VMXNET3 для лучшей производительности

# 2. Настройки ESXi хоста:
#    - Отключить CPU power management (Performance mode)
#    - Настроить NUMA affinity для PostgreSQL VM
#    - Использовать dedicated storage для PostgreSQL data

# 3. Настройки Storage:
#    - Использовать VMFS6 для лучшей производительности
#    - Настроить Storage I/O Control (SIOC) если необходимо
#    - Избегать oversubscription storage

# 4. Настройки Network:
#    - Использовать dedicated vSwitch для PostgreSQL
#    - Настроить Network I/O Control (NIOC) если необходимо
#    - Использовать jumbo frames если поддерживается

# 5. Мониторинг:
#    - Использовать vCenter для мониторинга производительности
#    - Настроить alerts для критических метрик
#    - Мониторить ESXi host performance
